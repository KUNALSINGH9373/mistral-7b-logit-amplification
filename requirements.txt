# Core Dependencies
torch>=2.0.0
transformers>=4.35.0
accelerate>=0.24.0

# Model quantization and optimization
bitsandbytes>=0.41.0  # For 4-bit and 8-bit quantization
peft>=0.7.0           # Parameter-Efficient Fine-Tuning (for LoRA if needed)

# Data and analysis
numpy>=1.24.0
pandas>=2.0.0
matplotlib>=3.7.0
seaborn>=0.12.0
scipy>=1.10.0         # For statistical analysis

# Jupyter & notebooks
jupyter>=1.0.0
ipython>=8.10.0
notebook>=7.0.0

# Utilities
python-dotenv>=1.0.0
tqdm>=4.65.0          # Progress bars
pyyaml>=6.0           # Configuration files
json5>=0.9.0          # Better JSON handling

# Hugging Face hub for model download
huggingface-hub>=0.17.0

# Optional: for distributed inference
# vllm>=0.1.0          # Uncomment if using vLLM for faster inference
