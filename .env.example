# Model Configuration
MODEL_ID=mistralai/Mistral-7B-Instruct-v0.2
CACHE_DIR=~/.cache/huggingface/hub

# Quantization Options: full, 8bit, 4bit
QUANTIZATION=8bit

# Experiment Parameters
MAX_TOKENS=100
TEMPERATURE=0.7
TOP_P=0.9

# Logging
LOG_LEVEL=INFO
SAVE_RESULTS=true
